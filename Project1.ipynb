{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The mnist.pkl.gz file is a gzipped version of a Python pickle file that contains the MNIST dataset. The structure of the unzipped pickle file is as follows:\n",
    "\n",
    "1.Training Set: This set is usually used to train the model.\n",
    "\n",
    "Images: A 2D array of shape (50000, 784). Each row corresponds to a flattened version of a 28x28 pixel image of a handwritten digit. The 784 values (28x28) are the pixel values (ranging from 0 to 255).\n",
    "Labels: A 1D array of shape (50000,). Each entry is an integer from 0 to 9 representing the label of the corresponding image.\n",
    "\n",
    "2.Validation Set: This set is typically used for tuning hyperparameters, and to avoid overfitting on the training data.\n",
    "\n",
    "Images: A 2D array of shape (10000, 784). Same structure as the training images.\n",
    "Labels: A 1D array of shape (10000,). Each entry represents the label of the corresponding image.\n",
    "\n",
    "3.Test Set: This set is used to evaluate the performance of the model after training.\n",
    "\n",
    "Images: A 2D array of shape (10000, 784). Same structure as the training and validation images.\n",
    "Labels: A 1D array of shape (10000,). Each entry represents the label of the corresponding image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Import necessary libraries:\n",
    "# numpy: A library for numerical computing in Python.\n",
    "# pickle: A module to serialize (convert data structures to bytes) and deserialize (convert bytes back to data structures) in Python.\n",
    "# gzip: A module to work with GZipped files.\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Load the MNIST dataset from pickle file\n",
    "def load_mnist(mnist):\n",
    "    # Use the \"gzip.open\" function to open the gzipped pickle file.\n",
    "    # 'rb' stands for 'read binary' because the file is a binary file.\n",
    "    with gzip.open(mnist, 'rb') as f:\n",
    "        # The \"encoding='bytes'\" is used because this pickle file might have been created with Python 2, \n",
    "        # and we're reading it with Python 3. This ensures compatibility.\n",
    "        training_data, validation_data, test_data = pickle.load(f, encoding='bytes')\n",
    "    return training_data, validation_data, test_data\n",
    "\n",
    "# Convert number labels to one-hot encoding\n",
    "# np.eye creates an identity matrix of size num_classes x num_classes.\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data, valid_data, test_data = load_mnist('mnist.pkl.gz')\n",
    "\n",
    "# Quick inspection\n",
    "datasets = {\"Training\": train_data, \"Validation\": valid_data, \"Test\": test_data}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    images, labels = data\n",
    "    print(f\"\\n{name} Data:\")\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    print(f\"Shape of images array: {images.shape}\")\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "    print(f\"Unique labels: {np.unique(labels)}\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_images, train_labels = train_data\n",
    "train_labels = one_hot_encode(train_labels)\n",
    "\n",
    "valid_images, valid_labels = valid_data\n",
    "valid_labels = one_hot_encode(valid_labels)\n",
    "\n",
    "test_images, test_labels = test_data\n",
    "test_labels = one_hot_encode(test_labels)\n",
    "\n",
    "# Define the Neural Network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias_hidden = np.zeros(hidden_size)\n",
    "        self.bias_output = np.zeros(output_size)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z_hidden = np.dot(x, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.a_hidden = self.sigmoid(self.z_hidden)\n",
    "        self.z_output = np.dot(self.a_hidden, self.weights_hidden_output) + self.bias_output\n",
    "        self.a_output = self.sigmoid(self.z_output)\n",
    "        return self.a_output\n",
    "      \n",
    "    def train(self, training_data, epochs, mini_batch_size, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size] for k in range(0, len(training_data), mini_batch_size)\n",
    "            ]\n",
    "\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, learning_rate)\n",
    "\n",
    "            # Print the training progress:\n",
    "            print(f\"Epoch {epoch + 1}: {accuracy(self, valid_images, valid_labels)}\")    \n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, learning_rate):\n",
    "        sum_gradient_wih = np.zeros(self.weights_input_hidden.shape)\n",
    "        sum_gradient_who = np.zeros(self.weights_hidden_output.shape)\n",
    "        sum_gradient_bh = np.zeros(self.bias_hidden.shape)\n",
    "        sum_gradient_bo = np.zeros(self.bias_output.shape)\n",
    "\n",
    "        for x, y in mini_batch:\n",
    "            gradient_wih, gradient_who, gradient_bh, gradient_bo = self.backpropagate(x, y)\n",
    "            sum_gradient_wih += gradient_wih\n",
    "            sum_gradient_who += gradient_who\n",
    "            sum_gradient_bh += gradient_bh\n",
    "            sum_gradient_bo += gradient_bo\n",
    "\n",
    "        self.weights_input_hidden -= learning_rate * sum_gradient_wih / len(mini_batch)\n",
    "        self.weights_hidden_output -= learning_rate * sum_gradient_who / len(mini_batch)\n",
    "        self.bias_hidden -= learning_rate * sum_gradient_bh / len(mini_batch)\n",
    "        self.bias_output -= learning_rate * sum_gradient_bo / len(mini_batch)\n",
    "\n",
    "    def backpropagate(self, x, y):\n",
    "        self.forward(x)\n",
    "        error_output = mse_prime(y, self.a_output) * sigmoid_prime(self.a_output)\n",
    "        error_hidden = np.dot(error_output, self.weights_hidden_output.T) * sigmoid_prime(self.a_hidden)\n",
    "        gradient_wih = np.dot(x.reshape(-1, 1), error_hidden.reshape(1, -1))\n",
    "        gradient_who = np.dot(self.a_hidden.reshape(-1, 1), error_output.reshape(1, -1))\n",
    "        return gradient_wih, gradient_who, error_hidden, error_output\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    ##return np.mean((y_true - y_pred) ** 2)\n",
    "    return np.sum((y_pred - y_true) ** 2) / (2 * len(y_true))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return np.sum(y_pred - y_true)/\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def accuracy(network, data_images, data_labels):\n",
    "    results = [(np.argmax(network.forward(x)), np.argmax(y)) for x, y in zip(data_images, data_labels)]\n",
    "    return sum(int(x == y) for (x, y) in results) / len(data_images)\n",
    "\n",
    "# Train the neural network\n",
    "nn = NeuralNetwork(784, 31, 10)\n",
    "nn.train(list(zip(train_images, train_labels)), epochs=30, mini_batch_size=10, learning_rate=0.5)\n",
    "\n",
    "# Test the neural network\n",
    "print(\"Accuracy on test data:\", accuracy(nn, test_images, test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
